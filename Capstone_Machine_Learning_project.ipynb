{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "16-wzPNxIThdMzLpAmko0ejxMhCZgCva0",
      "authorship_tag": "ABX9TyMMpHtycegkmciOmEtpYmYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyondurexpectation/Energy-Appliances-Project/blob/main/Capstone_Machine_Learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T1-FDpbIy_jw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJvnyLxxuifr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name-Appliance Energy Prediction**\n",
        "# **Project Type**-Supervised Machine Learning /Linear Regression/\n",
        "# **Created by**-Charanjeet Singh"
      ],
      "metadata": {
        "id": "vyZqUsQIurr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Github Link**\n"
      ],
      "metadata": {
        "id": "rYLJfx7Cwtqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Buisness Objective**-To make a model that predict the energy consumption of appliance by  taking  input such as temperature like living room tempertaure,Humidity ,Wind speed ,Visibility and predict the amount of energy consumed by appliance .Also to find how energy consumption increases or decreases with outisde tempertaure ,humidity and weather.\n"
      ],
      "metadata": {
        "id": "XVzRsw7OvPCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "QX6dj4wu0U3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "-vJpfd_QvOno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining Variable of data set**\n",
        "# **T1**-Temperature in kitchen area ,in Celsius\n",
        "# **T2**-Temperature in living room  ,in Celsius\n",
        "# **T3**-Temperature in laundary room ,in Celsius\n",
        "# **T4**-Temperature in office room  ,in Celsius\n",
        "# **T5**-Temperature in bathroom ,in Celsius\n",
        "# **T6**-Temperature outside the building (north side) ,in Celsius\n",
        "# **T7**-Temperature in ironing room ,in Celsius\n",
        "# **T8**-Temperature in teenager room 2 ,in Celsius\n",
        "# **T9**-Temperature in parent room ,in Celsius\n",
        "# **RH__-1**-Humidity in kitchen area ,in %\n",
        "# **RH-2**-Humidity in living room ,in %\n",
        "# **RH-3**-Humidity in laundary room ,in %\n",
        "# **RH-4**-Humidity in office room ,in %\n",
        "# **RH-5**-Humidity in bathroom ,in %\n",
        "# **RH-6**-Humidity outside the building (north side),in %\n",
        "# **RH-7**-Humidity in ironing room ,in %\n",
        "# **RH-8**-Humidity in teenager room 2,in %\n",
        "# **RH-9**-Humidity in parent room ,in %\n",
        "# **To**-Temperature outside (from chievres weather station),in Celsius\n",
        "# **Pressure**-(from chievres weather station)in mm Hg\n",
        "# **Hg RH-out**-Humidity outside (from chievres weather station) ,in %\n",
        "# **Wind speed**-(from chievres weather station),in m/s\n",
        "# **visibility**-(from chievres weather station),in Km\n",
        "# **Tdewpoint**-(from chievres weather station)\n",
        "# **Appliance(Energy used in Kwh)**-Depdent variable"
      ],
      "metadata": {
        "id": "IEa7LJWJzFWh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A671979NzFJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***IMPORTING LIBRARIES ***"
      ],
      "metadata": {
        "id": "Z5voZbya70-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso,LassoCV\n",
        "from sklearn.linear_model import Ridge,RidgeCV"
      ],
      "metadata": {
        "id": "IkTmCQQBvOk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#importing data\n",
        "data=pd.read_csv(r\"/content/drive/MyDrive/alma better/data_application_energy.csv\")\n",
        "#first look at data\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "UTsumYprvOh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "iflB4vFfvOfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.shape#there are 19735 rows and 29 columns in given data set"
      ],
      "metadata": {
        "id": "ueR4GRVzvOXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using describe function to get over view of data\n",
        "data.describe()#showing all numerical data value columns"
      ],
      "metadata": {
        "id": "wzjDLG9YvOHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking null values in given data set\n",
        "data.isnull().sum()\n",
        "data.isna().sum()\n",
        "#there is no null and missing  value in our data set\n"
      ],
      "metadata": {
        "id": "TUX-Nn43_e68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning and Manipulation**"
      ],
      "metadata": {
        "id": "zP_XYsTd_3O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#checking outlier in dependent variable\n",
        "sns.distplot(data['Appliances'])\n",
        "# we can clearly see there are some outlier in data so we will remove these  outliers"
      ],
      "metadata": {
        "id": "6vKQAxc1_e2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=data[['Appliances']]\n"
      ],
      "metadata": {
        "id": "csGS83hV_exU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"highest value of outlier\",data['Appliances'].mean()+data['Appliances'].std())\n",
        "print('lowest value of outlier',data['Appliances'].mean()-data['Appliances'].std())\n"
      ],
      "metadata": {
        "id": "3wevp0xx_etQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_data=data[(data['Appliances']>4.82)&(data['Appliances']<200.21)]\n",
        "new_data.shape\n",
        "\n",
        "#After removing outlier from our data we get new data set that is having 17819 rows and 29 columns"
      ],
      "metadata": {
        "id": "_PsyyTAc_eo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#plotting  density graph for new data\n",
        "sns.distplot(new_data['Appliances'])"
      ],
      "metadata": {
        "id": "1DRsLOIP_elA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LSsb_BmH4ByK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Univariate Analysis**\n",
        "Dividing data set variable in to three section\n",
        "\n",
        "\n",
        "# **1-Temperature_Section**\n",
        "# **2-Humidity_Section**\n",
        "# **3-Other_section**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oEfekjaI4Cn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature Section consist of temperature like Kitchen Area temperature,Living room ,dinning room ,laundry area,Bathroom temperature ,office room temperature ."
      ],
      "metadata": {
        "id": "oKAcsh3V5KEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Temperature section\n",
        "Temperature_section=['T1','T2','T3','T4','T5','T6','T7','T8','T9']\n",
        "print(len(Temperature_section))\n",
        "#performing analysis on temperature section and  we will check skewness of data\n",
        "for i in Temperature_section:\n",
        "  plt.figure(figsize=(4,5))\n",
        "  sns.distplot(new_data[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "eq80ncuy_egT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since we have ploted density plot for every element intemperaturesectionandwe can see that there is bell shaped curve that  mean there is no skewness in ploted data"
      ],
      "metadata": {
        "id": "6Yotsfu26-DR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing Analysis on Humditity section**"
      ],
      "metadata": {
        "id": "EBuT5f-779r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Humidity_section=['RH_1','RH_2','RH_3','RH_4','RH_5','RH_6','RH_7','RH_8','RH_9']\n",
        "for i in Humidity_section:\n",
        "  plt.figure(figsize=(4,5))\n",
        "  sns.distplot(new_data[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "ImORa6d7_edg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above graph we can see that there is no outlier but we cansee that all variable are not showing skewness that is all graph shape is not like bell shape so we have to take care of that"
      ],
      "metadata": {
        "id": "69HST4Gz-qii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.describe().columns"
      ],
      "metadata": {
        "id": "nPQHQwRC_wO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wR7_kmU_wJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#other section analysis\n",
        "Other_Section=['T_out', 'Press_mm_hg', 'RH_out', 'Windspeed', 'Visibility','Tdewpoint', 'rv1', 'rv2']\n",
        "for i in Other_Section:\n",
        "  plt.figure(figsize=(5,4))\n",
        "  sns.distplot(new_data[i])\n",
        "  plt.title(i)\n",
        "\n"
      ],
      "metadata": {
        "id": "AH6WPMKp-qPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine summary of Tempertaure,Humidity Section,Other section\n",
        "\n",
        "\n",
        "*   All humidity value follow normal distribution expect  RH6 AND RH_out\n",
        "   \n",
        "*   \n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "tcNYr_V5A3wX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evw-kO2I_eYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bivariate Analysis**"
      ],
      "metadata": {
        "id": "d3oTfz7Oc0kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we will create a column for weekdays and hourday\n",
        "#creating function to find date\n",
        "import datetime\n",
        "def fetch_hour(x):\n",
        "  return pd.to_datetime(x).hour\n",
        "def fetch_weekday(x):\n",
        "  return pd.to_datetime(x).weekday()\n",
        "new_data['hour']=new_data['date'].apply(fetch_hour)\n",
        "new_data['weekdays']=new_data['date'].apply(fetch_weekday)"
      ],
      "metadata": {
        "id": "KjNAGQKB_eVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data"
      ],
      "metadata": {
        "id": "X4_A9DDn_eRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating new data frame using group by function to perfor hour wise analysis\n",
        "weekened_data=pd.DataFrame(new_data.groupby(['weekdays'])['Appliances'].mean().reset_index())\n",
        "sns.barplot(x=weekened_data['weekdays'],y=weekened_data['Appliances'])\n"
      ],
      "metadata": {
        "id": "-nWkgBSu_eJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that energy consumption in weekend(0,5,6) is higher than other weekdays"
      ],
      "metadata": {
        "id": "Rk46gG_shtlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#analysing hour wise data and energy consumption\n",
        "hour_data=pd.DataFrame(new_data.groupby(['hour'])['Appliances'].mean().reset_index())\n",
        "sns.barplot(x=hour_data['hour'],y=hour_data['Appliances'])"
      ],
      "metadata": {
        "id": "Uldz6Rl5_eF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that energy consumption is higher in evening i.e from 16-20 hour energy cosnumption is higher"
      ],
      "metadata": {
        "id": "zY-r7ys5izIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing temperature and humidity"
      ],
      "metadata": {
        "id": "eG4nsBy1_eBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data['Average_temp']=0\n",
        "for i in Temperature_section:\n",
        "  new_data['Average_temp']=new_data['Average_temp']+new_data[i]\n",
        "new_data['Average_temp']=new_data['Average_temp']/len(Temperature_section)\n",
        "new_data\n",
        "\n",
        "Temp_data=pd.DataFrame(new_data.groupby(['weekdays'])['Average_temp'].mean().reset_index())\n",
        "sns.barplot(x=Temp_data['weekdays'],y=Temp_data['Average_temp'])"
      ],
      "metadata": {
        "id": "F_Fuxz7H_d-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that indoor temperature remain constant through out the week"
      ],
      "metadata": {
        "id": "jIKd43nMm-Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing average humditity\n",
        "#creating new data frame name average humidity\n",
        "new_data['Average_humidity']=0\n",
        "for i in Humidity_section:\n",
        "   new_data['Average_humidity']=new_data['Average_humidity']+new_data[i]\n",
        "new_data['Average_humidity']=new_data['Average_humidity']/len(Humidity_section)\n",
        "Average_humidity=pd.DataFrame(new_data.groupby(['weekdays'])['Average_humidity'].mean().reset_index())\n",
        "sns.barplot(x=Average_humidity['weekdays'],y=Average_humidity['Average_humidity'])\n"
      ],
      "metadata": {
        "id": "-FT34Pl3_d5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above graph we can see that avearge humidity remain same through out the weekdays"
      ],
      "metadata": {
        "id": "iI_zamrTpXrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analying variation of average temperature with respect to days hour\n",
        "hour_tempdata=pd.DataFrame(new_data.groupby(['hour'])['Average_temp'].mean().reset_index())\n",
        "hour_tempdata\n",
        "sns.barplot(x=hour_tempdata['hour'],y=hour_tempdata['Average_temp'])"
      ],
      "metadata": {
        "id": "UUtALGNh_d2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above Hour vs Average tempertaure analysis we can see that average temp all most remain same through out the day,we can see little bit of variation at some part of time but it is negligible"
      ],
      "metadata": {
        "id": "Zy2lw36otSDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nxNYoZP5tR82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # Analysing hour wise data vs average humidity\n",
        " #creating new data set named Hour_humidity\n",
        " Hour_humidity=pd.DataFrame(new_data.groupby(['hour'])['Average_humidity'].mean().reset_index())\n",
        " sns.barplot(x=Hour_humidity['hour'],y=Hour_humidity['Average_humidity'])"
      ],
      "metadata": {
        "id": "eJgHepIT_dzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above graph show that average humidity remain same  through out the day,but we can also see that  humidity for specific room changes little bit\n",
        "\n",
        "\n",
        "\n",
        "And we can see that Avearge temperature and humidity analysis does not give us any result"
      ],
      "metadata": {
        "id": "_9cW8aMOvnWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Analysing feature and weekdays to get some relation ship between  variable\n",
        "for i in new_data.columns[2:10]:\n",
        "  plt.figure(figsize=(4,5))\n",
        "  week_d=pd.DataFrame(new_data.groupby(['weekdays'])[i].mean().reset_index())\n",
        "  sns.barplot(x=week_d['weekdays'],y=week_d[i])\n"
      ],
      "metadata": {
        "id": "sJPwD2qA_dtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uFynFQRUup-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing other data paramter with respect to hour\n",
        "\n",
        "for i  in Other_Section:\n",
        "  plt.figure(figsize=(4,5))\n",
        "  new_1=pd.DataFrame(new_data.groupby(['hour'])[i].mean().reset_index())\n",
        "  sns.barplot(x=new_1['hour'],y=new_1[i])\n"
      ],
      "metadata": {
        "id": "fv28kkGFz7VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above analysis we can see that Outside Temperature and Humidity is varying with hour"
      ],
      "metadata": {
        "id": "X2mCLdtk1P6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#featuring data\n",
        "new_data['Energy_consumption']=new_data['Appliances'].apply(lambda x:('HIGH' if x>25 else 'LOW'))\n",
        "new_data['Energy_consumption']"
      ],
      "metadata": {
        "id": "RfktP62s0bHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now checking correlation\n",
        "#finding correlation between various feature of the data\n",
        "corr_1=new_data.corr()\n",
        "#PLOTTING  HEAT MAP CHART TO GET MORE INFORMATION\n",
        "plt.figure(figsize=(14,15))\n",
        "sns.heatmap(corr_1,annot=True,cmap='coolwarm')"
      ],
      "metadata": {
        "id": "bRN4gg_M2WL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here we can see that dats is highly correlated so we will  perform some process to reduce correlation"
      ],
      "metadata": {
        "id": "LigoLM7c9Cxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "knbmEtQ06FNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#removing multicolinearity by using variance inflation factor\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def VIF(X):\n",
        "  vif=pd.DataFrame()\n",
        "  vif['variable']=X.columns\n",
        "  vif['VIF']=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\n",
        "  return vif\n",
        "\n"
      ],
      "metadata": {
        "id": "DLwLmMEI-Tch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "VIF (new_data[[ i for i  in new_data.describe().columns if i not in ['Appliances','light']]])#'Appliances and light doesnot have any impact because they are dependent variable0"
      ],
      "metadata": {
        "id": "zy1ArT1Bw5WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see that T1 and T9 are showwing multicolineairty so we will remove one of them\n",
        "VIF(new_data[[i for i in new_data.describe().columns if i not in ['Appliances','weekdays','light','Average_humidity','Average_temp','T1','Press_mm_hg','T9','T2','rv1','rv2','RH_3','RH_4','T4','T5','T3','RH_1','RH_2','RH_8','T8','T7','RH_7','RH_9','T_out','Windspeed','RH_out','RH_5','RH_6']]])"
      ],
      "metadata": {
        "id": "nYe5uOkqxaGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new features are\n",
        "new_feature=['lights','T6','Visibility','Tdewpoint','hour']\n",
        "new_data[new_feature]"
      ],
      "metadata": {
        "id": "t53BPLuizTuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Model**"
      ],
      "metadata": {
        "id": "R9yir2jP3jsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore#SCALING DATA SET\n",
        "\n",
        "X=new_data[new_feature].apply(zscore)\n",
        "y=np.log10(new_data['Appliances'])\n",
        "y"
      ],
      "metadata": {
        "id": "4ojLJrXb2_-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data in to test and train set\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2)\n",
        "#checking shape of test and train data\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "id": "zppKcEjt8BeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of Linear Regression model**"
      ],
      "metadata": {
        "id": "8_EDd6Ch9NMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear=LinearRegression()\n",
        "regg=linear.fit(X_train,y_train)\n",
        "regg.score(X_train,y_train)\n",
        "regg.score(X_test,y_test)\n"
      ],
      "metadata": {
        "id": "C39LV9Rc8ntv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regg.coef_#values of cofficent\n",
        "regg.intercept_"
      ],
      "metadata": {
        "id": "UPYtFwZ-9eYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict=regg.predict(X_test)\n",
        "y_predict.shape"
      ],
      "metadata": {
        "id": "_jWzo9FD9u4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(y_test).shape)"
      ],
      "metadata": {
        "id": "haMl9vS199vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding mean square error of model using linear regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "MSE1=mean_squared_error(10**(y_test),10**(y_predict))\n",
        "print(\"Mean Square Error for test and predicted data is \",MSE1)"
      ],
      "metadata": {
        "id": "82Oh2QDt-DMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding root mean square error of predicted data\n",
        "RMSE=np.sqrt(MSE1)\n",
        "print(\"Root Mean Squared Error for test and predicted data is \",RMSE)\n",
        "#RMSE is very low that mean our model is not performing well on given data"
      ],
      "metadata": {
        "id": "L8HlStB6BLTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.plot(np.array(10**(y_test)[1:100]))\n",
        "plt.plot(10**(y_predict)[1:100])\n",
        "plt.legend(['Actual','Predicted'])"
      ],
      "metadata": {
        "id": "dUHYQ9jgFd_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we have large data set so to check to check model performance graphically we have loteed graph of Actual value and predicted value for 100 values"
      ],
      "metadata": {
        "id": "P-z_KSXoFdtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here we will use Lasso Regression for fitting our model and increase its efficency**"
      ],
      "metadata": {
        "id": "NSnw00RiC-DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso,LassoCV\n",
        "lasso=Lasso(alpha=.1,fit_intercept=True)\n",
        "lasso.fit(X_train,y_train)\n",
        "lasso.coef_\n",
        "print(lasso.intercept_)\n",
        "y_lasso_predict=lasso.predict(X_test)\n",
        "lasso.score(X_train,y_train)\n",
        "MSE2=mean_squared_error(10**(y_test),10**(y_lasso_predict))\n",
        "print(MSE2)\n",
        "RMSE2=np.sqrt(MSE2)\n",
        "print(RMSE2)"
      ],
      "metadata": {
        "id": "ddjfF6U4DREr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,8))\n",
        "plt.plot(np.array(10**(y_test))[1:100])\n",
        "plt.plot(10**(y_lasso_predict)[1:100])\n",
        "plt.legend(['Actual','Predicted'])\n",
        "plt.title(\"model performance after using laaso regression\")"
      ],
      "metadata": {
        "id": "E8Z4bBukE0W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using Ridge regression\n",
        "from sklearn.linear_model import Ridge,RidgeCV\n",
        "\n",
        "ridge_regressor=Ridge(alpha=.1,max_iter=3000,fit_intercept=True)\n",
        "ridge_regressor.fit(X_train,y_train)\n",
        "print(\"cofficent after applying ridge regression \",ridge_regressor.coef_)\n",
        "print(\"Intercept after applying rifge regression\",ridge_regressor.intercept_)"
      ],
      "metadata": {
        "id": "rfxETvrJK6IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ridge_predict=ridge_regressor.predict(X_test)\n",
        "y_ridge_predict\n"
      ],
      "metadata": {
        "id": "L7-epNS2MJZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking performance of model against predict and actual data\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.plot(np.array(10**(y_test))[1:100])\n",
        "plt.plot(10**(y_ridge_predict)[1:100])\n",
        "plt.legend(['Actual','Predict'])"
      ],
      "metadata": {
        "id": "jilHgwcaMWHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bfSmXhFJK5zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE3=mean_squared_error(10**(y_test),10**(y_ridge_predict))\n",
        "print(MSE3)\n",
        "RMSE3=np.sqrt(MSE3)\n",
        "print(\"root mean square error of ridge regression\",RMSE3)\n"
      ],
      "metadata": {
        "id": "eONKVcPmNEpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Cross Validation and Hyper parameter tuning**"
      ],
      "metadata": {
        "id": "CauKeai_CpIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using hyper parameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lasso=Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
        "Lasso_Regression=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n",
        "Lasso_Regression.fit(X_train,y_train)\n",
        "\n",
        "print(\"best alpha value after hyper parametering tuning\",Lasso_Regression.best_params_)\n",
        "#print(\"after using \",Lasso_Regression.best_params_,'best neg _mean_squared _error is',Lasso_Regression.best_score_)"
      ],
      "metadata": {
        "id": "CqgbTQw1BjsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting our model on tunned parameter\n",
        "y_tune_lasso=Lasso_Regression.predict(X_test)"
      ],
      "metadata": {
        "id": "R-mSqTBfKBpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tune_lasso"
      ],
      "metadata": {
        "id": "Cz6yxLYRKINT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE4=mean_squared_error(10**(y_test),10**(y_tune_lasso))\n",
        "print(MSE4)"
      ],
      "metadata": {
        "id": "73URpIPwQwo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RMSE4=np.sqrt(MSE4)\n",
        "print(RMSE4)"
      ],
      "metadata": {
        "id": "fAyA1kKuQyyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,12))\n",
        "plt.plot(10**(y_tune_lasso)[:100])\n",
        "plt.plot(np.array(10**(y_test))[:100])\n",
        "plt.legend(['Predicted values','Actual values'])"
      ],
      "metadata": {
        "id": "9z6WnhJ9TB_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performing hyper parameter tunning on Ridge regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "ridge=Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
        "Ridge_Regression=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\n",
        "Ridge_Regression.fit(X_train,y_train)\n",
        "\n",
        "print(\"best alpha value after hyper parametering tuning\",Ridge_Regression.best_params_)\n",
        "print(\"after using \",Ridge_Regression.best_params_,'best neg _mean_squared _error is',Ridge_Regression.best_score_)"
      ],
      "metadata": {
        "id": "mhPuZdNURfMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ridge_Regression.fit(X_train,y_train)\n",
        "y_predict_ridge=Ridge_Regression.predict(X_test)"
      ],
      "metadata": {
        "id": "GGgdsf3PSBhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE5=mean_squared_error(10**(y_test),10**(y_predict_ridge))\n",
        "print(MSE5)"
      ],
      "metadata": {
        "id": "kbQwFLyHSIyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RMSE5=np.sqrt(MSE5)\n",
        "print(RMSE5)"
      ],
      "metadata": {
        "id": "7AdBac-DSqpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting graph\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.plot(10**(y_predict_ridge)[:100])\n",
        "plt.plot(np.array(10**(y_test))[:100])\n",
        "plt.legend(['Predicted Value','Actual Value'])"
      ],
      "metadata": {
        "id": "VVB97w2KS2_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IDe1bQGWU4tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VtYvoSP9UX7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Values for R2 Score and MSE for different model are**\n",
        "\n",
        "1.   Linear Regression-  RMSE-28.42504,MSE-807.983\n",
        "2.   Lasso Regression-   RMSE-28.42533,MSE-807.9998\n",
        "3.   Ridge Regression-   RMSE-28.4266,MSE-808.076\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xoyg-IfGUIEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hence we  can see that we are getting same performance from all model"
      ],
      "metadata": {
        "id": "qf3kJ8p-UuZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}